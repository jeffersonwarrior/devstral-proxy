"""
Devstral Proxy - Core Proxy Logic

Handles the translation between OpenAI and Mistral API formats.
"""

import os
import json
import time
import logging
from typing import Dict, List, Any, Optional
from datetime import datetime, timedelta

import httpx
from fastapi import Request, Response
from fastapi.responses import JSONResponse

from .config import settings
from .utils import (
    log_message,
    normalize_content,
    convert_openai_to_mistral_message,
    validate_tool_call_correspondence,
    sanitize_request_body,
    sanitize_response_body,
)

logger = logging.getLogger("devstral_proxy")


class DevstralProxy:
    """
    Main proxy class handling request/response translation
    """
    
    def __init__(self):
        self.vllm_base = settings.VLLM_BASE
        self.debug = settings.DEBUG
        self.version = "1.0.0"
        self.start_time = datetime.now()
        
        # Tool call loop prevention
        self.tool_call_history = []  # Track recent tool calls
        self.max_tool_call_history = 10  # Max history to track
        self.loop_detection_window = 5  # Look back this many calls for patterns
        self.max_identical_calls = 3  # Max identical calls allowed in window
        
        # Rate limiting for tool calls
        self.tool_call_timestamps = []  # Track timing of tool calls
        self.max_tool_calls_per_minute = 30  # Rate limit
        
        # Circuit breaker
        self.circuit_breaker_triggered = False
        self.circuit_breaker_until = None
        
    def health_check(self) -> Dict[str, Any]:
        """
        Return health status and configuration
        """
        uptime = str(datetime.now() - self.start_time)
        
        return {
            "status": "ok",
            "proxy": "Devstral Proxy",
            "version": self.version,
            "uptime": uptime,
            "vllm_target": self.vllm_base,
            "debug_mode": self.debug,
            "timestamp": datetime.now().isoformat(),
        }
    
    async def handle_chat_completion(self, request: Request):
        """
        Handle chat completion requests
        
        Converts OpenAI format to Mistral format and forwards to VLLM server.
        """
        request_id = f"req-{int(time.time())}-{os.getpid()}"
        client_ip = request.client.host if request.client else "unknown"
        
        log_message(f"[{request_id}] Request from {client_ip}", level="info")
        
        try:
            start_time = time.time()
            
            # Parse request body
            try:
                body = await request.json()
                log_message(f"[{request_id}] Request: {json.dumps(body, indent=2, default=str)}", level="debug")
            except json.JSONDecodeError as e:
                log_message(f"[{request_id}] Invalid JSON: {str(e)}", level="error")
                return JSONResponse(
                    content={"error": f"Invalid JSON: {str(e)}"},
                    status_code=400,
                )
            
            # Sanitize and convert request
            try:
                sanitized_body = sanitize_request_body(body)
                
                # Log tool information if present
                original_tools = body.get("tools", [])
                if original_tools:
                    tool_names = [tool.get("function", {}).get("name", "unknown") for tool in original_tools]
                    log_message(f"[{request_id}] Found {len(original_tools)} tools: {', '.join(tool_names)}", level="info")
                
                # Check for tool calls in messages
                tool_call_count = 0
                for msg in body.get("messages", []):
                    if msg.get("role") == "assistant" and msg.get("tool_calls"):
                        tool_call_count += len(msg["tool_calls"])
                
                if tool_call_count > 0:
                    log_message(f"[{request_id}] Found {tool_call_count} tool calls in messages", level="info")
                    
                    # Check for circuit breaker
                    if self.circuit_breaker_triggered and datetime.now() < self.circuit_breaker_until:
                        log_message(f"[{request_id}] CIRCUIT BREAKER ACTIVE - Blocking tool calls until {self.circuit_breaker_until}", level="warning")
                        return JSONResponse(
                            content={"error": "Tool calls temporarily disabled due to excessive usage"},
                            status_code=429,
                        )
                    
                    # Check rate limiting
                    if self._check_rate_limit():
                        log_message(f"[{request_id}] RATE LIMIT EXCEEDED - Blocking tool calls", level="warning")
                        return JSONResponse(
                            content={"error": "Too many tool calls. Please try again later."},
                            status_code=429,
                        )
                
                log_message(f"[{request_id}] Sanitized request: {json.dumps(sanitized_body, indent=2, default=str)}", level="debug")
            except Exception as e:
                log_message(f"[{request_id}] Sanitization error: {str(e)}", level="error")
                return JSONResponse(
                    content={"error": f"Request sanitization failed: {str(e)}"},
                    status_code=400,
                )
            
            # Forward to VLLM server
            try:
                async with httpx.AsyncClient(timeout=settings.TIMEOUT) as client:
                    # Forward headers (excluding sensitive ones)
                    fwd_headers = {
                        k: v for k, v in request.headers.items()
                        if k.lower() not in {"host", "content-length", "accept-encoding"}
                    }
                    
                    log_message(f"[{request_id}] Forwarding to {self.vllm_base}", level="debug")
                    
                    resp = await client.post(
                        f"{self.vllm_base}/v1/chat/completions",
                        json=sanitized_body,
                        headers=fwd_headers,
                    )
            except httpx.HTTPError as e:
                log_message(f"[{request_id}] VLLM connection error: {str(e)}", level="error")
                return JSONResponse(
                    content={"error": f"VLLM server error: {str(e)}"},
                    status_code=502,
                )
            
            # Process response
            try:
                response_data = resp.json()
                sanitized_response = sanitize_response_body(response_data)
                
                # Log tool call information from response
                if "choices" in sanitized_response:
                    for i, choice in enumerate(sanitized_response["choices"]):
                        if "message" in choice and "tool_calls" in choice["message"]:
                            tool_calls = choice["message"]["tool_calls"]
                            if tool_calls:
                                tool_names = [tc.get("function", {}).get("name", "unknown") for tc in tool_calls]
                                log_message(f"[{request_id}] Response contains {len(tool_calls)} tool calls: {', '.join(tool_names)}", level="info")
                                
                                # Check for tool call loops
                                if self._detect_tool_call_loop(tool_calls):
                                    log_message(f"[{request_id}] POTENTIAL LOOP DETECTED - Blocking repeated tool calls", level="warning")
                                    
                                    # Check if this is a legitimate VIBE request
                                    if not self._is_legitimate_vibe_request(body):
                                        log_message(f"[{request_id}] NON-VIBE REQUEST BLOCKED - Suspected loop", level="warning")
                                        return JSONResponse(
                                            content={"error": "Potential tool call loop detected. Request blocked."},
                                            status_code=400,
                                        )
                                    else:
                                        log_message(f"[{request_id}] VIBE REQUEST ALLOWED - Legitimate tool usage", level="info")
                                
                                # Log each tool call details
                                for j, tool_call in enumerate(tool_calls):
                                    func_name = tool_call.get("function", {}).get("name", "unknown")
                                    func_args = tool_call.get("function", {}).get("arguments", "{}")
                                    log_message(f"[{request_id}] Tool call {j+1}: {func_name}({func_args})", level="debug")
                
                duration = time.time() - start_time
                log_message(f"[{request_id}] Response: {resp.status_code} in {duration:.3f}s", level="info")
                log_message(f"[{request_id}] Response: {json.dumps(sanitized_response, indent=2, default=str)}", level="debug")
                
                return JSONResponse(
                    content=sanitized_response,
                    status_code=resp.status_code,
                    media_type="application/json",
                )
            except json.JSONDecodeError:
                return Response(
                    content=resp.content,
                    status_code=resp.status_code,
                    media_type=resp.headers.get("content-type", "application/json"),
                )
    def _check_rate_limit(self) -> bool:
        """
        Check if tool calls are being made too frequently
        """
        now = datetime.now()
        # Remove old timestamps (older than 1 minute)
        self.tool_call_timestamps = [
            ts for ts in self.tool_call_timestamps 
            if (now - ts).total_seconds() < 60
        ]
        
        # Check if we've exceeded the limit
        if len(self.tool_call_timestamps) >= self.max_tool_calls_per_minute:
            # Trigger circuit breaker for 5 minutes
            self.circuit_breaker_triggered = True
            self.circuit_breaker_until = now + timedelta(minutes=5)
            return True
        
        # Add current timestamp
        self.tool_call_timestamps.append(now)
        return False
    
    def _detect_tool_call_loop(self, tool_calls: List[Dict[str, Any]]) -> bool:
        """
        Detect if we're in a tool call loop
        """
        if not tool_calls:
            return False
        
        # Create a signature for this tool call
        call_signature = self._create_tool_call_signature(tool_calls)
        
        # Add to history
        self.tool_call_history.append({
            "signature": call_signature,
            "timestamp": datetime.now()
        })
        
        # Keep history within limits
        if len(self.tool_call_history) > self.max_tool_call_history:
            self.tool_call_history = self.tool_call_history[-self.max_tool_call_history:]
        
        # Check for repeated patterns in the detection window
        recent_calls = self.tool_call_history[-self.loop_detection_window:]
        signature_count = sum(1 for call in recent_calls if call["signature"] == call_signature)
        
        if signature_count > self.max_identical_calls:
            log_message(f"LOOP DETECTED: {signature_count} identical tool calls in window", level="warning")
            return True
        
        return False
    
    def _create_tool_call_signature(self, tool_calls: List[Dict[str, Any]]) -> str:
        """
        Create a signature for a set of tool calls to detect patterns
        """
        # Sort tool calls by function name for consistent signature
        sorted_calls = sorted(
            tool_calls, 
            key=lambda x: x.get("function", {}).get("name", "")
        )
        
        # Create signature from function names and arguments
        signature_parts = []
        for call in sorted_calls:
            func_name = call.get("function", {}).get("name", "unknown")
            func_args = call.get("function", {}).get("arguments", "{}")
            signature_parts.append(f"{func_name}({func_args})")
        
        return ", ".join(signature_parts)
    
    def _is_legitimate_vibe_request(self, body: Dict[str, Any]) -> bool:
        """
        Check if this request appears to be from VIBE CLI (legitimate)
        """
        # VIBE CLI requests typically have specific patterns
        messages = body.get("messages", [])
        
        # Check for VIBE-specific patterns
        for msg in messages:
            content = msg.get("content", "")
            if isinstance(content, str):
                # VIBE CLI often mentions specific tools or has structured requests
                if any(keyword in content for keyword in ["search_replace", "read_file", "grep", "bash", "todo"]):
                    return True
        
        # Check if tools are reasonable (not system prompt)
        tools = body.get("tools", [])
        if tools:
            tool_names = [tool.get("function", {}).get("name", "") for tool in tools]
            # VIBE tools are specific
            if any(name in ["search_replace", "read_file", "write_file", "grep", "bash", "todo"] for name in tool_names):
                return True
        
        return False
            
        except Exception as e:
            log_message(f"[{request_id}] Unexpected error: {str(e)}", level="error")
            if self.debug:
                import traceback
                log_message(f"[{request_id}] Traceback: {traceback.format_exc()}", level="error")
            
            return JSONResponse(
                content={"error": f"Proxy error: {str(e)}"},
                status_code=500,
            )